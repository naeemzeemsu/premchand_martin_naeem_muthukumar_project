{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5if8juGWYn4"
      },
      "outputs": [],
      "source": [
        "# CSE 404 Machine Learning Project NFL combine data to HOF percentage\n",
        "# Group Members: Pranav Premchand, Daphne Martin, Zeeshan Naeem, Pranesh Muthukumar\n",
        "\n",
        "# Data in combine data folder named as qb combine data.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "# Step 1: Load and prepare the data\n",
        "data = pd.read_csv(\"qb_combine_data.csv\")  # Load the QB combine data\n",
        "\n",
        "# Preprocess height column to separate feet and inches\n",
        "data['Height_Feet'] = data['Ht'].apply(lambda x: int(x.split(\"'\")[0]))\n",
        "data['Height_Inches'] = data['Ht'].apply(lambda x: int(x.split(\"'\")[1].replace('\"', '')))\n",
        "\n",
        "X = data[['Height_Feet', 'Height_Inches', 'Wt', '40yd', 'Vertical', 'Broad Jump', '3Cone', 'Shuttle']]  # Features\n",
        "y = data['Hof']  # Target variable (continuous)\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2.1: Handle missing values with mean imputation\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "# Reshape input data for LSTM\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        "\n",
        "# Step 3: Build and train the support vector regression model\n",
        "svr_model = SVR()  # Default SVR\n",
        "svr_model.fit(X_train_imputed, y_train)\n",
        "\n",
        "# Step 4: Build and train the Ridge (L2 regularization) model\n",
        "ridge_model = Ridge(alpha=0.1)  # You can adjust the alpha parameter for tuning the strength of regularization\n",
        "ridge_model.fit(X_train_imputed, y_train)\n",
        "\n",
        "# Step 5: Build and train the Lasso (L1 regularization) model\n",
        "lasso_model = Lasso(alpha=0.1)  # You can adjust the alpha parameter for tuning the strength of regularization\n",
        "lasso_model.fit(X_train_imputed, y_train)\n",
        "\n",
        "# Step 6: Build and train the LSTM model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),  # LSTM layer\n",
        "    Dropout(0.2),  # Dropout layer to prevent overfitting\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "lstm_model.fit(X_train_reshaped, y_train, epochs=20, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Step 7: Evaluate the models\n",
        "svr_mse = mean_squared_error(y_test, svr_model.predict(X_test_imputed))\n",
        "ridge_mse = mean_squared_error(y_test, ridge_model.predict(X_test_imputed))\n",
        "lasso_mse = mean_squared_error(y_test, lasso_model.predict(X_test_imputed))\n",
        "lstm_mse = mean_squared_error(y_test, lstm_model.predict(X_test_reshaped))\n",
        "\n",
        "print(\"Support Vector Regression Mean Squared Error:\", svr_mse)\n",
        "print(\"Ridge Regression Mean Squared Error:\", ridge_mse)\n",
        "print(\"Lasso Regression Mean Squared Error:\", lasso_mse)\n",
        "print(\"LSTM Mean Squared Error:\", lstm_mse)\n",
        "\n",
        "# Define a fixed random seed\n",
        "random.seed(42)\n",
        "\n",
        "# Step 8: Define function to predict HOF percentage for a single player's combine data\n",
        "def predict_hof_percentage(height_feet, height_inches, weight, forty_yard, vertical_jump, three_cone, shuttle):\n",
        "    # Count the number of missing inputs\n",
        "    missing_inputs = [forty_yard, vertical_jump, three_cone, shuttle].count(None)\n",
        "\n",
        "    if missing_inputs >= 3:\n",
        "        # If 3 or more inputs are missing, apply a flat 30% boost to all Hall of Fame scores\n",
        "        boost = 1.3  # 30%\n",
        "    else:\n",
        "        boost = 0\n",
        "\n",
        "    # Apply weights to features\n",
        "    weights = {\n",
        "        '40yd': 0.4,\n",
        "        'Vertical': 0.3,\n",
        "        'Height_Feet': 0.1,\n",
        "        'Wt': 0.1,\n",
        "        '3Cone': 0.05,\n",
        "        'Shuttle': 0.05\n",
        "    }\n",
        "\n",
        "    # Fill None values with averages\n",
        "    imputed_forty_yard = X_train['40yd'].mean() if forty_yard is None else forty_yard\n",
        "    imputed_vertical_jump = X_train['Vertical'].mean() if vertical_jump is None else vertical_jump\n",
        "    imputed_three_cone = X_train['3Cone'].mean() if three_cone is None else three_cone\n",
        "    imputed_shuttle = X_train['Shuttle'].mean() if shuttle is None else shuttle\n",
        "\n",
        "    # Scale the features based on weights\n",
        "    scaled_forty_yard = imputed_forty_yard * weights['40yd']\n",
        "    scaled_vertical_jump = imputed_vertical_jump * weights['Vertical']\n",
        "    scaled_height_weight = ((height_feet * 12 + height_inches) / 100 + weight / 300) * weights['Height_Feet']\n",
        "    scaled_three_cone = imputed_three_cone * weights['3Cone']\n",
        "    scaled_shuttle = imputed_shuttle * weights['Shuttle']\n",
        "\n",
        "\n",
        "    # Calculate the predicted Hall of Fame percentage using SVR\n",
        "    scaled_features = np.array([[scaled_height_weight, scaled_forty_yard, scaled_vertical_jump, weight, imputed_forty_yard, imputed_vertical_jump, imputed_three_cone, imputed_shuttle]])\n",
        "    scaled_features_imputed = imputer.transform(scaled_features)\n",
        "    scaled_features_scaled = scaler.transform(scaled_features_imputed)\n",
        "    scaled_features_reshaped = scaled_features_scaled.reshape(1, 1, scaled_features_scaled.shape[1])\n",
        "\n",
        "    # Predict Hall of Fame percentage using each model\n",
        "    svr_hof_percentage = svr_model.predict(scaled_features_imputed)[0]\n",
        "    ridge_hof_percentage = ridge_model.predict(scaled_features_imputed)[0]\n",
        "    lasso_hof_percentage = lasso_model.predict(scaled_features_imputed)[0]\n",
        "    lstm_hof_percentage = lstm_model.predict(scaled_features_reshaped)[0]\n",
        "\n",
        "    # Add 30% boost to all Hall of Fame scores\n",
        "    svr_hof_percentage += boost * svr_hof_percentage\n",
        "    ridge_hof_percentage += boost * ridge_hof_percentage\n",
        "    lasso_hof_percentage += boost * lasso_hof_percentage\n",
        "    lstm_hof_percentage += boost * lstm_hof_percentage\n",
        "\n",
        "    return svr_hof_percentage, ridge_hof_percentage, lasso_hof_percentage, lstm_hof_percentage\n",
        "\n",
        "# Inputs for the hof prediction function\n",
        "height_feet = 6\n",
        "height_inches = 1\n",
        "weight = 216 # pounds\n",
        "forty_yard = None # seconds\n",
        "vertical_jump = None # inches\n",
        "three_cone = None # seconds\n",
        "shuttle = None # seconds\n",
        "\n",
        "svr_hof_percentage, ridge_hof_percentage, lasso_hof_percentage, lstm_hof_percentage = predict_hof_percentage(height_feet, height_inches, weight, forty_yard, vertical_jump, three_cone, shuttle)\n",
        "print(\"Predicted Hall of Fame Percentage (SVR):\", svr_hof_percentage*100)\n",
        "print(\"Predicted Hall of Fame Percentage (Ridge):\", ridge_hof_percentage*100)\n",
        "print(\"Predicted Hall of Fame Percentage (Lasso):\", lasso_hof_percentage*100)\n",
        "print(\"Predicted Hall of Fame Percentage (LSTM):\", lstm_hof_percentage*100)\n"
      ],
      "metadata": {
        "id": "vuS8zw5ldnKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f286d5d-352c-4766-9974-c14a5bb869a2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3/3 [==============================] - 4s 918ms/step - loss: 0.0212 - val_loss: 0.0777\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0192 - val_loss: 0.0734\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0199 - val_loss: 0.0702\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0198 - val_loss: 0.0681\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0190 - val_loss: 0.0671\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0173 - val_loss: 0.0667\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0176 - val_loss: 0.0666\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0174 - val_loss: 0.0667\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0174 - val_loss: 0.0670\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0175 - val_loss: 0.0675\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0163 - val_loss: 0.0679\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0177 - val_loss: 0.0683\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0165 - val_loss: 0.0686\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0173 - val_loss: 0.0691\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0157 - val_loss: 0.0693\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0159 - val_loss: 0.0693\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0164 - val_loss: 0.0692\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0163 - val_loss: 0.0692\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0158 - val_loss: 0.0691\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0169 - val_loss: 0.0690\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "Support Vector Regression Mean Squared Error: 0.06390573231342837\n",
            "Ridge Regression Mean Squared Error: 0.0669366343869932\n",
            "Lasso Regression Mean Squared Error: 0.0672040207656592\n",
            "LSTM Mean Squared Error: 0.06735296571694052\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted Hall of Fame Percentage (SVR): 25.438747551824285\n",
            "Predicted Hall of Fame Percentage (Ridge): -560.0231942275033\n",
            "Predicted Hall of Fame Percentage (Lasso): 11.668634453781513\n",
            "Predicted Hall of Fame Percentage (LSTM): [93.53237]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}